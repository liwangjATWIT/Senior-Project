# -*- coding: utf-8 -*-
"""LLM Training

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mel7u_OEvrEj9Sbbi2pFJ63VnMDQceXi

# Test for AI.
"""

!pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git" -q
!pip install --no-deps "tr1<0.9.0" peft accelerate bitsandbytes xformers datasets -q

from unsloth import FastLanguageModel as FLM
import torch

max_seq_length = 2048
dtype = None
load_in_4bit = True

model, tokenizer = FLM.from_pretrained(
    model_name = "unsloth/gemma-2b",
    max_seq_length = max_seq_length,
    dtype = dtype,
    load_in_4bit = load_in_4bit
)

FLM.for_inference(model)

alpaca_prompt = """Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{}

### Input:
{}

### Response:
{}"""

instruction = "You are a helpful assistant who can answer questions"
input = "Who is Virat Kohli?"

# process the input
inputs = tokenizer([alpaca_prompt.format(instruction, input, "")], return_tensors='pt').to('cuda')
outputs = model.generate(**inputs, max_new_tokens=100)
response = tokenizer.batch_decode(outputs)[0]
print(response)

!pip install datasets

"""def generate_prompt(example):
    return f"Generate a travel itinerary for a trip to city {example['city_id']} in {example['hotel_country']} from {example['checkin']} to {example['checkout']}."

Added an new row called promp.

Data Clean Up
"""

from datasets import load_dataset
import pandas as pd
import ast

# Load the dataset dict
dataset = load_dataset('osunlp/TravelPlanner', 'train')  # Already gets the 'train' Dataset
print(dataset)

# Convert the train split to a pandas DataFrame
train_dataset = dataset['train']

# Convert to pandas DataFrame
df = train_dataset.to_pandas()


# Optionally drop unwanted columns
df = df.drop(columns=[
    'query', 'level',
    'budget', 'local_constraint',
    'people_number', 'visiting_city_number'
])

# Convert stringified lists in 'date' to actual lists
def safe_parse_date_column(val):
    if isinstance(val, list):
        return val
    if isinstance(val, str):
        try:
            return ast.literal_eval(val)
        except (ValueError, SyntaxError):
            return []
    return []

df['date'] = df['date'].apply(safe_parse_date_column)

# Extract start and end dates
df['start_date'] = df['date'].apply(lambda x: x[0] if x else None)
df['end_date'] = df['date'].apply(lambda x: x[-1] if x else None)

# Drop original 'date' column
df = df.drop(columns=['date'])

trip_rows = []

for idx, row in df.iterrows():
    # Parse the stringified list into a real Python object
    annotated_plan = ast.literal_eval(row['annotated_plan'])

    # Get trip metadata and itinerary
    trip_info = annotated_plan[0]  # Metadata dictionary
    itinerary_list = annotated_plan[1]  # List of day-wise plans

    for day_plan in itinerary_list:
        if not day_plan:  # Skip empty days
            continue
        trip_rows.append({
            'trip_org': trip_info['org'],
            'trip_dest': trip_info['dest'],
            'days': trip_info['days'],
            'people': trip_info['people_number'],
            'budget': trip_info['budget'],
            'day': day_plan['days'],
            'current_city': day_plan['current_city'],
            'transportation': day_plan['transportation'],
            'breakfast': day_plan['breakfast'],
            'attraction': day_plan['attraction'],
            'lunch': day_plan['lunch'],
            'dinner': day_plan['dinner'],
            'accommodation': day_plan['accommodation']
        })

# Convert to DataFrame
itinerary_df = pd.DataFrame(trip_rows)

print(itinerary_df.head())

df = df.drop(columns=['annotated_plan'])

# Export to CSV
# df.to_csv('cleaned_travelplanner.csv', index=False)
# print("Data exported to cleaned_travelplanner.csv")

# Show first 5 rows
print(df.head(1))
# print(df['annotated_plan'][0])

